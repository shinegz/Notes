## 基础概念

### 什么是 WebGL

WebGL(Web Graphics Library) 是一个用于绘制交互式 2D/3D 图形的 JavaScript API，基于 OpenGL ES 2.0。



### WebGL 程序

WebGL 程序由 JavaScript 的控制代码，和在计算机的图形处理单元（GPU, Graphics Processing Unit）中执行的着色器代码（shader code，由 OpenGL Shading Language（GLSL）编写）组成。

**GLSL** - **OpenGL Shading Language** 也称作 **GLslang**，是一个以C语言为基础的高阶着色语言。它是由 OpenGL ARB 所建立，提供开发者对图形管线更多的直接控制（**可编程**），而无需使用汇编语言或硬件规格语言。

着色器程序（shader program）使得开发者可以控制图形管线过程中的关键部分，其本质上是一种把输入转化为输出的程序，有两类：

+ 顶点着色器（vertex shader）：它以一组顶点（vertex）属性作为输入并输出一组新的属性。
+ 片段着色器（fragment shader）：它以一个像素作为输入并输出像素的颜色、深度、贴图和光照等值。



### 计算机图形

计算机图形是使用计算机创建的图片和电影。 

使用计算机描述图片有两种基本方法：

+ 光栅图形 ：使用许多小颜色点描述图片。每个点称为一个像素，是“图片元素”的简称。如果这些点足够小并且靠得足够近，一个人就看不到单个点，而是看到一张“图片”。
+ 矢量图形 ：使用数学方程将对象描述为几何形状。图片是通过称为渲染的过程根据数学描述创建的。渲染的结果是二维光栅图像。



#### 简史

<img src=".\WebGL\webgl_history.png" style="zoom:50%;" />

##### OpenGL

+ 1992 年：OpenGL 1.0 - 用于创建计算机图形的固定功能管线。程序员将顶点数据输入管线并输出 3D 渲染。
+ 2004 年：OpenGL 2.0 - GPU 变得可编程。程序员可以编写会在 GPU 中执行的着色器程序，图形管线可编程。固定功能管线程序和着色器程序不兼容。
+ 2008 年：OpenGL 3.0 - 图形数据从 CPU RAM 移动到 GPU 内存以加快渲染速度。
+ 2010 年：OpenGL 4.0 - 高级着色器语言功能和高级纹理映射。
+ 2014 年：OpenGL 4.5 - 最新版本。



##### OpenGL ES

OpenGL ES（OpenGL for Embedded Systems）是为了适应手机、游戏机等嵌入式设备，由 OpenGL 裁减定制而来的，去除了glBegin/glEnd，四边形（GL_QUADS）、多边形（GL_POLYGONS）等复杂图元等许多非绝对必要的特性。





### 图形管线

**图形管线**（Graphics pipeline）是计算机图形系统将**对象的矢量图形表示**渲染为**光栅图像**的一系列步骤。

| Pipeline Step:                                               | Description:                                                 | Performed by:                            |
| :----------------------------------------------------------- | :----------------------------------------------------------- | :--------------------------------------- |
| ![step1_image](http://learnwebgl.brown37.net/_images/pipeline_input.jpg) | 将数据输入管道，包括定义位置的模型顶点 (x,y,z)、定义方向的法线向量 (dx,dy,dz) 和颜色数据。 | CPU: JavaScript code                     |
| ![step2_image](http://learnwebgl.brown37.net/_images/pipeline_model_transform.jpg) | 将模型平移、缩放和旋转到 3D 场景中所期望的位置和方向上。然后将所有东西移到镜头前。 | CPU: JavaScript codeGPU: Vertex Shader   |
| ![step3_image](http://learnwebgl.brown37.net/_images/pipeline_projection_transform.jpg) | 将 3D 世界投射到 2D 显示屏幕上。                             | CPU: JavaScript codeGPU: Vertex Shader   |
| ![step4_image](http://learnwebgl.brown37.net/_images/pipeline_normalize.jpg) | 裁剪掉不在相机视野中的所有东西。                             | CPU: JavaScript codeGPU: Vertex Shader   |
| ![step5_image](http://learnwebgl.brown37.net/_images/pipeline_viewport_transform.jpg) | 将 3D 对象的坐标映射为光栅图像中的像素坐标                   | GPU: Fixed functionality                 |
| ![step6_image](http://learnwebgl.brown37.net/_images/pipeline_rasterize.jpg) | 确定每个对象（点、线或三角形）覆盖了哪些像素，并丢弃被其他对象完全遮挡的对象。 | GPU: Fixed functionality                 |
| ![step7_image](http://learnwebgl.brown37.net/_images/pipeline_shading.jpg) | 确定代表一个对象的每个像素的颜色。                           | CPU: JavaScript codeGPU: Fragment Shader |
| ![step8_image](http://learnwebgl.brown37.net/_images/pipeline_composting.jpg) | 将像素的颜色添加到光栅图像，可能会将颜色与图像中已有的颜色组合。 | GPU: Fixed functionality                 |
| ![step9_image](http://learnwebgl.brown37.net/_images/pipeline_output.jpg) | 输出一个光栅图像，图像的每个像素带有一个颜色值。             | GPU: Fixed functionality                 |



## 模型数据

要创建虚拟世界的渲染，我们需要能够描述这个世界。我们假设虚拟世界是对象的集合，然后使用数学方法对对象进行描述，这个数学描述就叫做对象的模型。

虚拟世界中的对象有如下几个方面的属性：

+ 位置
+ 方向
+ 体积
+ 表面



### <u>位置</u>

位置永远是相对的。全局原点 局部原点

在 WebGL 中，采用齐次坐标系（homogeneous coordinates），或者称为投影坐标（projective coordinates）来确定位置，它是一个四分量值（x, y, z, w），前三个值 x、y、z 是沿笛卡尔坐标系轴的距离，最后一个 w 用于透视计算。



### 方向

和位置不同，方向可以是相对的，也可以是绝对。

+ 相对方向与对象的当前位置和方向有关。
+ 绝对方向相对于确定的参考系，并且始终指向同一方向，与对象的位置无关。

#### 向量

向量是用来表示方向的标准方式。向量可以用一端带有箭头的线端来表示，没有箭头的一端称为“尾”，有箭头的一端称为“头”。

向量定义为沿每条参考线从尾部到头部的变化，在二维的笛卡尔坐标系内，用 <dx, dy> 表示。一个向量实际上表示了两个东西：方向和距离（或长度）。方向由头部的箭头指出，距离则是从尾部到头部的长度。如果一个向量的长度为一个单位长度，那么这个向量就称为“单位向量”。转换为单位向量后，<dx, dy> 值相同的向量，方向也相同。将一个向量转换为单位向量称为“归一化”。

![](.\WebGL\VectorImage.png)

+ 绝对方向

  由 <dx, dy> 表示的向量有方向，但没有位置，这样的向量表示了确定的坐标系下的一个绝对方向。一个特定的绝对方向的归一化表示是唯一的。

  下图中，3个蓝色向量都是相同的，绿色向量和蓝色向量的方向相同，但长度不同。

  ![](.\WebGL\VectorsNotUniqueImage.png)

+ 相对方向

  如果要使用向量表示相对方向，则需要一个向量和特定的尾部位置。一对值（点，向量）表示一个相对方向。如下图所示，点（2, 3）和向量 <3, 1> 表示特定位置（2, 3）处的一个相对方向。

  ![](.\WebGL\VectorRelativeImage.png)



### 外形

一个3维对象可能是一个立方体、一个球体、一个平面或一个复杂的多面体。对象的形状可以有无数种，以独特的方式描述每个对象是可能的，但这需要为每个对象使用独特的渲染算法，这显然是不科学的。所以我们需要用一种统一的方式来描述任何形状的对象，而不管其形状的复杂程度。这个统一的方式为三角形。

为什么是三角形？因为：

+ 三角形是定义封闭区域的最简单的几何形状。三角形有一个内部区域和一个外部区域。

+ 三角形总是平面的。它总是定义一个平面。

+ 三角形将3维空间划分为三个不同的区域。3维空间中的所有点都位于：

  + 由三角形定义的平面中
  + 在平面的一侧
  + 在平面的另一侧

  按照惯例，我们可以说三角形的一侧是正面，另一侧是背面。通过组合三角形，我们可以创建具有内部和外部的形状。

+ 三角形总是凸的，渲染凹多边形比渲染凸多边形更难。

#### 三角形的定义

一个三角形由三个点（位置）定义，这三个点**各不相同**，并且**不在一条线上**。

**顶点**

三角形的三个点定义了三个边或边界线段。这三个点是边界线段相交的位置，被称为顶点。

**三角形面**

包围在其边内的三角形的表面通常称为三角形的面。一个三角形有两个面，前面和背面。对于观察者而言，一次只能看到它的一个面。

三角形顶点的顺序（缠绕顺序）用于确定三角形的哪一边是正面。如果一个三角形顶点的顺序是逆时针顺序，那么按照惯例，这个面就是三角形的正面。

<img src=".\WebGL\winding_order.png" style="zoom:67%;" />

**法向量**

背向三角形正面且与三角形表面上的每个点都成直角的向量称为法向量。

<img src=".\WebGL\normal_vectors.png" style="zoom:67%;" />



#### 对象的定义

任何3维对象的形状都可以用称为三角形网格的一组三角形来近似。

<img src=".\WebGL\Dolphin_triangle_mesh.png" style="zoom:50%;" />

对象形状的精确性取决于用于对其进行建模的三角形数量。并且总是有以下权衡：

+ 使用最少数量的三角形，这意味着对象的形状是一个粗略的近似值，但使用很少的内存渲染非常快。 
+ 使用多个三角形，这意味着对象的形状是准确的，但渲染需要更多时间，并且 RAM 和 GPU 内存要求要大得多。

<img src=".\WebGL\triangle_mesh_quality.jpeg" style="zoom: 33%;" />

#### 三角形渲染模式

在 WebGL 中，使用顶点数组来定义一组三角形。通过顶点定义三角形的方式有三种：

+ TRIANGLES：每个三角形需要三个顶点。每个顶点只能用于一个三角形。用于多个三角形的顶点必须在顶点数组中重复。定义 n 个三角形需要 3n 个顶点。
+ TRIANGLE_STRIP：在最初的三个顶点之后，每个额外的顶点又定义了一个三角形。定义 n 个三角形需要 (n + 2) 个顶点。
+ TRIANGLE_FAN：所有三角形共享第一个顶点。在前两个顶点之后，每个新顶点又创建一个三角形。定义 n 个三角形需要 (n + 2) 个顶点。

![](.\WebGL\triangle_drawing_modes2.png)



### 表面

除了对对象的外形进行建模外，还需要对它的表面属性进行建模。表面属性包括但不限于：

+ 表面的颜色是什么？颜色是纯色还是多色？
+ 表面如何反射光？它是闪亮的还是沉闷的？
+ 表面是否光滑、粗糙或凹凸不平？
+ 表面是平的还是弯曲的？
+ 表面是否透明以允许一些光线穿过它？如果是这样，光是否会折射（改变其传播方向）？

所有这些表面属性基本上都是一个问题，即光如何从表面反射到人的眼睛（或相机的镜头）中。因此，渲染对象的最终外观是对象表面属性与光交互的结果。

#### 颜色

模型表面最基本的表面属性就是它的颜色。

##### 颜色模型

+ RGB

  对于使用光产生图像的设备，例如计算机显示器，颜色被建模为三种基色的组合：红色、绿色和蓝色。光是可加的。如果以全强度添加红色、绿色和蓝色光，则会得到白光。没有光会产生黑色。人眼可辨别的所有颜色都可以使用红、绿和蓝光的某种组合来创建。这称为 RGB（红、绿、蓝）颜色系统。

+ CMY

  对于从反射光产生图像的设备（例如打印页面），颜色被建模为三种基色的组合：青色、品红色和黄色。这些颜料吸收某些波长的光，基本上反射红、绿和蓝光。所以这并不是一种真正不同的颜色表示方式，它只是一种产生反射光的不同方式。可以使用青色、品红色和黄色颜料的某种组合来创建打印页面上人眼可辨别的所有颜色。这称为 CMY（青色、品红色、黄色）颜色系统。

WebGL 使用的是 RGB 颜色系统，需要三个值来表示特定颜色：红、绿和蓝光的量。将这些值设为百分比是有意义的：0% 表示没有颜色，而 100% 表示全强度颜色。由设备的硬件来确定 100% 的全强度颜色意味着什么。

##### 设备独立的颜色

WebGL 实现了图形的跨平台显示。实现设备独立的颜色的标准方案是使用浮点值，用于表示颜色强度的浮点值的二进制位数称为颜色的深度。一般人只能看到特定颜色的大约250种深浅的变化。下图显示了不同颜色深度选择下黑色到白色之间的过渡变化。

<img src=".\WebGL\bitdepths_chart_med.jpg" style="zoom:33%;" />

+ 不同颜色深度的色带中，每个颜色块都是一种纯色。
+ 对于大多数人来说，8位色深提供了平滑的颜色渐变，这也是眼睛的最大颜色分辨率。
+ 8位色深允许256种不同的黑白色调。如果为每个 RGB 分量值使用8位，则可以表示超过1600万种不同的颜色。(2^8)^3对于普通人来说，这种色彩精度称为“全彩”。

##### 透明度

透明的物体允许一些光穿过它，对象的透明度可以根据其组成而有很大的差异。一种比较简单的透明度模型是存储带有颜色值的“不透明度百分比”，这个百分比称为“阿尔法值”。RGBA 就是一种带透明度的颜色系统，为一种颜色存储4个分量值，其中前三个值是红色、绿色和蓝色分量，最后一个值是阿尔法值。如下是一些示例：

| RGBA color             | Opaque（不透明）                                             | Transparent（透明） |
| :--------------------- | :----------------------------------------------------------- | :------------------ |
| (0.2, 0.1, 0.9, `1.0`) | opaque, all light is reflected                               | 0% transparent      |
| (0.2, 0.1, 0.9, `0.9`) | mostly opaque                                                | 10% transparent     |
| (0.2, 0.1, 0.9, `0.5`) | half the light passed through the object                     | 50% transparent     |
| (0.2, 0.1, 0.9, `0.0`) | all light travels through the the object, the object is invisible | 100% transparent    |



#### 纹理映射

现实世界的物体的表面很少是纯色的，所以我们需要一种能够对具有多种颜色的表面进行建模的方法，纹理映射就是这样的一种方法。

##### 什么是映射

在数学中，映射是将一组输入转换为输出值的函数。有两种基本方法可以做到这一点：

+ 对输入执行计算以产生输出值。
+ 从可能值列表中查找输出值。这称为“表查找”。

在计算机图形学中，映射的输出通常是某种图案，因此我们将输入到输出的转换称为纹理映射。纹理映射允许我们为模型表面的每个像素分配不同的颜色。根据实现映射的方法，可以将纹理映射分为两种：

##### 程序纹理映射

程序纹理映射是一个通过计算将输入值转换为颜色的函数。计算的结果既可以用于选择颜色，也可以用于直接生成颜色。计算产生的可能图案的数量是没有限制的，下面的示例生成一个 10 像素宽的黑白棋盘图案：

```glsl
function checkerboard(x,y) {
  if ( floor(x/10) + floor(y/10) mod 2 == 1) {
    color = [ 0, 0, 0, 1]; // black
  } else {
    color = [ 1, 1, 1, 1]; // white
  }
  return color;
}
```

输入值可以是你想要基于着色的任何值，一维纹理映射接收单个输入值并返回颜色，二维纹理映射接收两个输入值并返回颜色，依次类推，三维纹理映射接收三个。

##### 图像纹理映射

“表查找”纹理映射通常使用图像完成。一个图像本质上是一个颜色值的二维数组，给定行和列值，返回图像中特定位置像素的颜色。在伪代码中，这样的纹理映射看起来像这样：

```glsl
function getColor(image, x, y) {
  return image[x][y]; // the color of the indicated pixel
}
```

图像是为模型表面指定一组颜色值的便捷方式，但是，图像始终是矩形，而 WebGL 仅呈现三角形。我们需要一种方法来指定图像内的哪些像素包含三角形面的颜色。这种方法称为“纹理坐标”，“纹理坐标”指定图像中的哪个位置对应于三角形的顶点。

为了使纹理坐标适用于任何图像，位置以百分比指定。例如，0.0 是图像的左边缘，1.0 是右边缘，0.5 是中间。下图显示了一个示例，顶点 B 被映射到纹理坐标为 (0.31, 0.74) 的图像中的特定位置，因为我们希望在顶点 B 处显示的图像中的颜色距离左边缘 31%，距离底部边缘 74%，一旦三个 3D 顶点映射到图像中的相应位置，就可以轻松计算内部位置。

<img src=".\WebGL\texture_coordinate_example.jpg" style="zoom:67%;" />

WebGL 支持程序和基于图像的纹理映射。

+ 程序纹理映射是通过在片段着色器中编写函数来执行的。
+ 基于图像的纹理映射通过以下方式执行：
  + 从服务器下载适当的图像。
  + 创建 GPU 纹理对象并将图像保存到 GPU 的内存中。
  + 在片段着色器中使用表查找功能从图像中获取特定像素的颜色。



#### 表面法向量

表面法向量是被用来计算模型表面颜色的表面基本属性。使用法向量的方式具有多种，不同的方式将带来不同的视觉渲染效果。

+ 每个三角形一个法向量

  ![](.\WebGL\one_normal_per_face.png)

  这是默认的使用方式。单个三角形面上的每个像素都将具有相同的颜色，这种渲染方式被称为“平面着色”。 

+ 每个顶点一个法向量

  ![](.\WebGL\one_normal_per_vertex.png)

  如果为每个顶点指定不同的法向量，则可以为每个顶点计算不同的颜色。

  如果从顶点颜色开始向内插值得到整个三角形面中每个像素的颜色，面将具有弯曲外观（与平面外观相反）。（这种技术以其发明者的名字命名，称为 Gouraud 着色）

  如果从三角形面的顶点开始向内插值得到法向量，然后使用插入的法向量重新计算片段颜色，将使整个三角形面获得更准确的着色。这种方法需要更长的时间来计算，但可以提供更平滑的颜色渐变，这种着色方式为 Phong 着色。

  这两种着色都称为“平滑着色”。

+ 每个像素一个法向量

  ![](.\WebGL\one_normal_per_pixel.png)

  通过为每个像素指定唯一的法线向量来控制三角形表面上单个像素的颜色。这是通过图像纹理映射来完成的，其中图像中的每个“像素”不被视为 RGB 值，而是作为 <dx,dy,dz> 法线向量。



#### 光

要模拟对象在现实世界中的外表，必须得模拟光如何与对象的表面相互作用。当光线照射到物体时，会发生以下四种情况中的一种或多种：

+ 光线在物体表面沿不同方向反射。反射光的方向由物体的表面特性决定。
+ 光被物体吸收并转化为能量，随着时间的推移加热物体。（这称为吸收。）
+ 光穿过物体并继续前进，但轨迹发生变化。（光从物体穿过称为透射，其方向的变化称为折射。）
+ 光进入物体，在物体内部反弹，然后在与它撞击的不同位置离开物体。（这称为次内表面散射。）

##### 光源

在现实世界中，光来自光源。太阳是最明显的光源，其他光源包括灯、聚光灯、火和爆炸，光的特性根据其来源而变化。如果我们希望获得合理的渲染效果，我们需要对光源的基本属性进行建模。光源有如下基本属性：

+ 位置，即光从哪里来，有两种情况：
  + 定向：光源距离很远，以至于所有光线基本上都沿同一方向传播。太阳是定向光源。
  + 位置性：光源就在场景内，光线照射物体的角度根据它们的相对位置而变化。
+ 颜色，由于光可以有不同的颜色，可以使用 RGB 值对光进行建模。红光是 (1.0, 0.0, 0.0) ，白光是 (1.0, 1.0, 1.0)。
+ 光照的方向，光是向所有方向传播（发散光），还是光被限制在特定方向（聚光）。



###### 光源类型



##### 光类型

###### 环境反射光

> 场景周围存在的光，但没有任何可辨别的来源。所有模型的所有面部都被环境光照亮。

环境光是“背景”光。它向四面八方到处反射，没有特定的起源位置。环境光照亮模型的每一个面，因此，获得直射光的面和隐藏在直射光后的面都被相同数量的环境光照亮。



###### 漫反射光

> 当一束平行的光照射到物体上，由于粗糙的表面上的各点的法线方向不一致，造成反射光线向不同的方向无规则地反射，这种反射的光称为漫反射光。



###### 镜面反射光

> 当一束平行的光照射到光滑的表面时，表面上各点的法线方向一致，反射光线沿同一方向反射，这种反射的光称为镜面反射光。

如果物体是光滑的，则从物体表面反射的一些光可以直接反射到观察者的眼睛（或相机的镜头）中。这会创建一个“镜面高光”，它是光源的颜色，而不是物体的颜色。图像中蓝色球上的每个白色区域都是镜面高光。

<img src=".\WebGL\specular_highlight.png" style="zoom:50%;" />

物体表面上的镜面高光的位置由从观察者到物体表面上的点的射线与反射光射线之间的角度决定。反射光射线根据表面法向量计算得来。

![](.\WebGL\specular_highlight_rays.png)

WebGL 中的所有光的作用效果都由片段着色器中的程序决定。要实现上述三种光的作用效果，需要执行以下操作：

+ 从光源模型中获取环境光。
+ 计算表面法向量和光方向之间的角度。
+ 将角度的余弦乘以表面的漫反射颜色。
+ 计算反射光和相机方向之间的角度。
+ 将角度的余弦乘以光源模型的镜面反射颜色。
+ 相加环境、漫反射和镜面反射光的颜色，该颜色即三角形表面这个片段的像素颜色。



##### 光的合并





## 模型变换

模型变换即改变模型形状、位置或方向的操作：缩放、位移、旋转。

这三个变换都不会改变模型的基本属性，在对模型应用这三个变换中的一个或它们的任何组合后：

+ 变换前相互平行的线，在变换后依然是平行的
+ 在变换前组成一条线的点，在变换后仍然组成一条线
+ 保持距离比。变换前线的中点仍然是变换后线的中点

具有上面三种特性的变换被称为仿射变换，对于这种变换，我们可以只对模型的顶点应用变换，就能实现整个模型的变换。

### 位移

位移会改变模型的位置，但不会影响模型的大小和方向。在数学上，位移是一个简单的加法。

位移通过向模型顶点的每个分量添加一个值来实现，将顶点（x,y,z）位移到（x',y',z'）：

```
x' = x + tx;
y' = y + ty;
z' = z + tz;
```

### 缩放

缩放主要是用来改变模型的大小的，但它也可以移动和翻转模型。在数学上，缩放是一个简单的乘法。

通过缩放模型顶点的3个分量值（x,y,z）实现整个模型的缩放，根据对顶点三个分量缩放的比例是否相同，分为均匀缩放和非均匀缩放。

均匀缩放使用当个比例因子s来更改顶点的3个分量：

```
x' = x * s; 
y' = y * s; 
z' = z * s;
```

非均匀缩放对每个分量使用不同的比例因子进行缩放：

```
x' = x * sx; 
y' = y * sy; 
z' = z * sz;
```

### 旋转

旋转主要用来改变模型的方向，但如果模型不在原点处时，也会改变模型位置。

### 变换矩阵



## 相机

### 投影和视口







## 渲染

### 预处理

在开始渲染场景前，会进行一些预处理操作：

1. 获取用于呈现渲染图像的 HTML canvas 元素。
2. 获取 canvas 元素的 WebGL 上下文，通常称为 *gl*。
3. 为 *gl* 上下文设置所需的状态。
4. 将顶点着色器和片段着色器程序编译并链接到渲染程序（在 GPU 中执行，用于生成图像的程序）中。
5. 获取对渲染程序中变量的引用，以便在渲染时设置它们的值。
6. 对于场景中的每个模型：
   1. 将 OBJ 模型数据存入相应地数组中，以便渲染使用。
   2. 创建一个缓冲区对象，用于在 GPU 内存中存储模型数据。
   3. 将数组中的模型数据填充到缓冲区对象中。



### 渲染步骤

每次渲染场景时，执行步骤如下：

1. 清除渲染缓冲区，该缓冲区用于保存渲染结果（像素图像）。
2. 选择着色器程序。
3. 对于场景中的每个模型：
   1. 将 `uniform` 值复制到着色器程序。
   2. 将存储有顶点数据的缓冲区对象链接到着色器程序中的变量，以获取 `attribute` 值。
   3. 调用 WebGL `gl.drawArrays()` 函数。
   
   渲染模型的步骤示意图如下： 

![](.\WebGL\rendering_steps.png)



### 着色器程序

着色器程序分为顶点着色器和片段着色器两部分，分别用于处理单个顶点和单个片段，并且每次只能处理一个顶点和一个片段，在图形管线中被自动调用。

在着色器程序执行前，必须将模型的数据存入 GPU 中的缓冲区，该存储空间是一个着色器程序可以直接快速访问的连续内存块，里面存储的是一维数组，模型的数据可以使用数组索引来获取。

当渲染模型时，需要通过 JavaScript 代码告诉着色器程序从顶点对象缓冲区获取哪些顶点数据，当调用`gl.drawArrays(mode, first, count)`时，会从`array[first]`位置开始渲染`count`个顶点，`mode`参数决定这些顶点如何被用于渲染图形元素，绘制模式有如下几种：

<img src=".\WebGL\drawing_modes.png"  />

顶点着色器的工作是为一个名为 `gl_Position` 的特殊变量赋值一个由 4 个值 (x,y,z,w) 组成的向量，该值将传递到管线的下一个阶段——“视口变换”阶段，此阶段会将顶点的位置转换为渲染图像中的像素位置。这个像素位置（及其相关的渲染数据）被传递到下一个阶段——“光栅化器”，“光栅化器”会确定模型所覆盖的所有像素，然后将每个像素及其相关的渲染数据传递给片段着色器进行着色（用于计算单个像素的颜色的一组数据称为一个片段）。

片段着色器的工作是将 RGBA 颜色值分配给名为 ` gl_FragColor ` 的特殊变量。该颜色被传递到图形管线的“合成”阶段，颜色值用于更新正在创建的光栅图像。

总的来说，顶点着色器负责定位模型的顶点，片段着色器负责为顶点所定义的对象模型所覆盖到的所有像素分配一种颜色。

![](.\WebGL\pipeline.png)



### 着色器、缓冲区和图形管线

每当 JavaScript 程序调用 `gl.drawArrays(mode, start, count)` 时，存储在缓冲区对象中的 `count` 个顶点会被传入图形管线，在图形管线中会为每个顶点调用一次顶点着色器程序，伪代码如下：

```glsl
for (j = start; j < count; j += 1) {
  call vertex_shader(vertex_buffer[j]);
}
```

如果要创建复杂的图形，顶点和片段着色器需要的不仅仅是位置数据，还需要包括颜色、法线向量、纹理坐标等数据。由于图形管线针对渲染速度进行了优化，因此其他数据必须按照与顶点数据相同的顺序组织在数组中。如果每个顶点都有额外的属性，上面的伪代码就变成了这样：

```glsl
for  ( j  =  start ;  j  <  count ;  j  +=  1 )  { 
  call  vertex_shader ( vertex_buffer [ j ],  color_buffer [ j ],  normal_vector_buffer [ j ],  ...);
}
```

这是 WebGL 渲染的一个重要的基本原则。由于管线的工作方式，所有数据都必须以“每个顶点”为基础进行组织。这意味着在某些情况下，其他数据必须在数组中多次复制才能与顶点数据“匹配“，这对于内存使用可能非常低效，但它使渲染速度非常快。为了说明这个原理，假设您想使用特定颜色渲染一个三角形，您必须创建一个数组来存储每个单独顶点的颜色，即使所有三个顶点都具有相同的颜色。下面的代码显示了存储了 3 个顶点，9 个值的数组。如果顶点的颜色来自缓冲区对象中的数组，颜色必须存储三次才能与顶点数据“匹配”。在下面的示例中，颜色“红色”被存储了 3 次。

```javascript
var  triangle_vertices  =  [ 0 , 0 , 0 ,  1 , 6 , 2 ,  3 , 4 , 1 ]; 
var  triangle_color     =  [ 1 , 0 , 0 ,  1 , 0 , 0 ,  1 , 0 , 0 ]
```

