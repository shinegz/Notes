## 概述

操作系统是计算机系统中最基本的系统软件，位于底层硬件与应用程序之间，是两者沟通的桥梁。操作系统向下管理和抽象各种计算资源，向上为应用程序提供运行环境和开发支持，为用户提供交互界面。（管理 + 服务）

以下是操作系统的简略架构示意图：

![](.\操作系统\操作系统简略架构.png)

### 操作系统简史



### 计算机硬件结构

从宏观上看，现在主流的计算机依然采用冯●诺伊曼结构，其包括三个主要部分：

+ 中央处理单元（Central Processing Unit，CPU）
+ 存储器（memory unit）
+ 输入输出（Input and Output，I/O）

#### CPU架构与指令集架构

##### CPU架构

CPU 架构是 CPU 厂商给属于同一系列的CPU产品定的一个规范，主要目的是为了区分不同类型 CPU 的重要标示。目前市面上的 CPU 分类主要分有两大阵营，一个是 intel、AMD 为首的复杂指令集 CPU，另一个是以 IBM、ARM 为首的精简指令集 CPU。两个不同品牌的 CPU，其产品的架构也不相同，例如，Intel、AMD的CPU是 X86 架构的，而 IBM 公司的 CPU 是 PowerPC 架构，ARM 公司是 ARM 架构。

##### 指令集架构

指令集架构（Instruction Set Architecture，ISA）是 CPU 和软件之间的桥梁。ISA 包含指令集、特权级、寄存器、执行模式、安全扩展、性能加速扩展等诸多方面。

指令集架构常见种类如下： 

+ 复杂指令集运算（Complex Instruction Set Computing，CISC）
+ 精简指令集运算（Reduced Instruction Set Computing，RISC） 

###### 指令集

指令集包含一系列不同功能的指令，用于数据搬移、计算、内存访问、过程调用等。CPU 在运行操作系统或应用程序时，实际上是在执行它们被编译后所包含的指令。

每款 CPU 在设计时就规定了一系列与其硬件电路相配合的指令系统，从现阶段的主流体系结构讲，指令集可分为复杂指令集和精简指令集两部分。

AArch64（ARMv8-AArch64）体系结构的指令集属于精简指令集计算机（Reduced Instruction Set Computer，RISC）。AArch64 中每条指令的长度固定为4字节，指令类型包括：

+ 数据搬移指令（如 mov）；
+ 寄存器计算指令（如加法指令 add、减法指令 sub）；
+ 内存读写指令（如内存加载指令 ldr、内存写入指令 str）；
+ 跳转指令（如无条件跳转指令 b）;
+ 过程调用指令（如调用指令 bl、返回指令 ret）；
+ 特权指令（如读取系统寄存器指令 msr、写入系统寄存器指令 mrs）等。



###### 特权级

为了确保操作系统的安全，CPU 提供了一种特权级隔离机制，使 CPU 在执行应用程序和操作系统内核的指令时处于不同的特权级。特权级的高低代表着操控硬件能力的强弱，在低特权级下不允许执行高特权级下才能执行的指令。

AArch64 中的特权级被称为异常级别，共有四种特权级：

+ EL0：最低的特权级，应用程序通常运行在该特权级，也称为**用户态**。
+ EL1：操作系统通常运行在该特权级，也称为**内核态**
+ EL2：在虚拟化场景下需要，虚拟机监控器通常运行在该特权级。
+ EL3：和安全特性 TrustZone 相关，负责**普通世界**和**安全世界**之间的切换。

TrustZone 从逻辑上将整个系统分为安全世界和普通世界，计算资源可以被划分到这两个世界中。安全世界可以不受限制地访问所有的计算资源，而普通世界不能访问被划分到安全世界的计算资源。



###### 寄存器





#### 物理内存与CPU缓存

##### 缓存结构

##### 缓存寻址



#### 设备与中断

##### 内存映射输入输出

> 内存映射输入输出（Memory-Mapped I/O，MMIO）是一种常见的CPU控制和访问设备的方式。其原理是：把输入输出设备和物理内存存放在同一个地址空间，为设备内部的内存和寄存器也分配相应的地址。

##### 轮询与中断

> CPU可以通过MMIO配置的地址获取设备输入，但CPU还需要知道是否有输入事件发生。
>
> 通过轮询的方式，CPU需要不断去查看设备是否有输入，这种方式比较浪费CPU资源，一种更高效的方式是采用中断机制，设备通过主动向CPU发出中断来打断CPU的执行，使得CPU去处理这个中断。

MIMO使得CPU可以主动地访问设备，中断使得设备能够主动地通知CPU，这两种机制是CPU与设备之间交互的重要方式。





### 操作系统结构

广义的操作系统分为操作系统内核与操作系统框架两层，操作系统**内核**负责对硬件资源的管理与抽象，为操作系统框架提供基础的系统服务；操作系统**框架**则基于操作系统内核提供的服务为不同的应用领域提供编程接口与运行环境。 

#### 系统复杂度管理方法

管理复杂系统的重要方法是 M.A.L.H 方法，即**模块化**（modularity）、**抽象**（abstraction）、**分层**（layering）和**层级**（hierarchy）。

+ 模块化：通过“分而治之”（divide and conquer）原则，将一个复杂系统分解为一系列**通过**明确定义的**接口**进行**交互**的模块，并严格保障模块之间的界限。

+ 抽象：在模块化的基础上，将**接口**与**内部实现**分离，从而使模块之间只需通过抽象的接口进行相互调用，而无须关心模块的内部实现。

良好的模块化和抽象可以很好地将一个大系统分解成一系列能够较好地进行交互的模块。不过，对于一个大的复杂系统而言，一个可能的结果是分解的模块会比较多，相互的交互关系会非常复杂，因此需要进一步通过分层与层级来控制复杂度。

+ 分层：分层是通过将模块按照一定的原则进行层次的划分，约束**每层内部模块间的交互方式**与**跨层次模块间的交互方式**，从而有效地减少模块之间的交互。（一个模块只能和同层模块以及相邻的上层或下层模块进行交互）
+ 层级：层级是另一种模块的组织方式。首先将一些功能相近的模块组成一个具有清晰接口的自包含子系统，然后再将这些子系统递归地组成一个具有清晰接口的更大子系统。

M.A.L.H 是操作系统中降低复杂度与组织各种功能模块的有效方法。



#### 内核架构

##### 简要

简要结构的特征是不区分用户态和内核态，应用程序和操作系统都放置在同一个地址空间中。应用程序对操作系统的调用可直接通过函数调用高效完成。



##### 宏内核

宏内核（Monolithic kernel）又称单内核，其特征是操作系统内核的所有模块均运行在内核态，具备直接操作硬件的能力，应用程序运行在用户态。



##### 微内核

将宏内核架构下的操作系统内核的模块从内核中拆分出来，作为独立的服务运行在用户态，内核中仅保留极少的功能，为这些服务提供通信等基础能力，这样的架构称为微内核（Microkernel）。



##### 外核

##### 多内核



#### 系统框架结构





## 进程管理

### 进程与线程

#### 进程

操作系统**资源分配**的基本单位。

每个进程都通过一个数据结构来保存它的基本信息和相关状态，如它的进程标识符（Process IDentifier，PID）、进程状态、虚拟内存状态、打开的文件等。这个数据结构称为**进程控制块**（Process Control Block，PCB）。

进程的创建、销毁和上下文（进程在运行过程中的状态）切换，都是指对 PCB 的操作。

#### 线程

操作系统**运算调度**的基本单位。针对进程间数据不易共享、通信开销高等问题，操作系统在进程内部引入了更加轻量级的执行单元，即线程（thread）。

线程是**进程内部**可**独立执行**的单元，它们共享进程的地址空间，但又各自拥有自己的**线程控制块**（Thread Control Block，TCB），用于保存**运行时所需的状态**（即上下文）。



#### 区别

Ⅰ 拥有资源

进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问隶属进程的资源。

Ⅱ 调度

线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

Ⅲ 系统开销

由于创建或撤销进程时，系统都要为之分配或回收资源，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

Ⅳ 通信方面

线程间可以通过直接读写同一进程中的数据进行通信，但是进程通信需要借助 IPC。



### 进程状态的切换

<img src=".\操作系统\进程状态.png" style="zoom:50%;" />

进程可以处于以下几种状态：

+ 新生状态（created）：该状态表示一个进程刚刚被创建出来，还未完成初始化，不能被调度执行。
+ 就绪状态（ready）：该状态表示进程可以被调度执行，但还未被调度器选择。
+ 运行状态（running）：该状态表示进程正在 CPU 上运行。
+ 阻塞状态（blocked）：该状态表示进程需要等待外部事件（如某个 I/O 请求的完成），暂时无法被调度。当进程等待的外部事件完成后，它会迁移至就绪状态。
+ 终止状态（terminated）：该状态表示进程已经完成了执行，且不会再被调度。



### 进程调度

进程调度的本质是资源的分配，如何协调多个进程对 CPU、内存和 I/O 资源的使用是调度器的主要任务。进程调度根据职责的不同，具体分为长期、中期、短期调度。

+ 长期调度：长期调度的触发间隔将长，它粗粒度地**决定是否**应该将一个**新的进程纳入调度管理**，负责增加系统中可被调度的进程的数量。用于**限制**系统中真正**被短期调度管理**的**进程数量**，避免短期调度的开销过大。
+ 短期调度：短期调度触发频繁，它负责细粒度地**调度进程的执行**，做出相应的调度决策。当长期调度为某个程序创建了进程并将其状态设置为就绪状态后，会由短期调度进一步**管理该进程**。
+ 中期调度：中期调度的触发相对频繁，它辅助**换页机制**，负责**限制**系统中**可被调度**的**进程的数量**。当当前系统中的进程已经占用了大量内存时，中期调度会挂起系统中被短期调度管理的进程（例如频繁触发缺页异常的进程、长时间未响应的进程等），进而**降低**进程**占用的内存总量**。当中期调度将就绪状态或阻塞状态的进程挂起后，进程将无法被短期调度执行，直到在合适的时机将其激活，才可被重新调度。

![](.\操作系统\基于进程调度的进程状态转换.png)

长期调度负责调控系统整体；中期调度是换页机制的一部分，负责监控内存资源的使用；只有短期调度能够决定任务是否可以执行，以下是短期调度相关的调度策略：

#### 单核调度策略



#### 多核调度策略



### 进程同步

### 进程间通信

每个进程都有自己的一部分独立的系统资源，彼此是隔离的。为了能使不同的进程互相访问资源并进行协调工作，需要进行进程间通信，进程间通信（Inter-Process Communication，IPC）是多进程协作的基础。

#### 基本概念

##### 数据传递

进程间通信的一个重要功能是在进程间传递数据。消息传递（将数据抽象成一个个的消息进行传递）是 IPC 中常用的数据传递方式。

###### 基于共享内存的消息传递

操作系统内核为通信的进程在它们的虚拟地址空间中映射了同一段物理内存，然后在这块共享内存上建立数据结构，这样进程就可以共享该共享区域上的数据了。

###### 操作系统辅助的消息传递

操作系统辅助的消息传递是指内核对用户态提供通信的接口，如 Send 和 Recv 等，进程可以直接使用这些接口，将消息传递给另一个进程，而不需要建立共享内存和轮询内存数据等操作。



##### 控制流转移

对于操作系统内核来说，实现消息传递机制除了考虑数据的传输外，往往还会附带控制流转移的功能：当通信发生时，内核将控制流从发送者切换到接收者进程（返回过程类似）。通过控制流转移可以避免轮询操作，高效地将消息的到来和发出“告知”进程。



##### 单向和双向

单向通信指的是消息在一个连接上只能从一端发送到另一端，双向则允许双方互相发送消息。而单向和双向均可的方式则会根据通信中具体的配置选项来判断是否需要支持单向或双向的通信。

##### 同步和异步

同步 IPC 指它的 IPC 操作会阻塞进程直到该操作完成。调用者发起 IPC 请求，然后控制流切换到被调用者；被调用者处理请求时，调用者会处于阻塞的状态；当被调用者执行完任务后，控制流会切回调用者，调用者拿到返回的结果后才可以继续执行。

异步 IPC 则是非阻塞的，进程只要发起一次操作即可返回，而不需要等待其完成。当调用者发起 IPC 后，被调用者接收到通信的数据和请求后开始响应；而同时，调用者的 IPC 调用不会等待被调用者执行，而是直接返回。异步 IPC 通常通过轮询内存状态或注册回调函数来获取返回结果。



##### 超时机制

进程间的隔离性使得通信的双方很难确认对方的状态，当控制流从调用者切换到被调用者后，如果被调用者恶意地不返回到调用者，或者被调用者因为某些错误导致一些请求被丢失，就会导致调用者无法继续执行。为了解决这个问题，IPC 的设计中引入了超时机制。超时机制扩展了 IPC 通信双方的接口，运行发送者/接收者指定它们发送/接收请求的等待时间，如果超过等待时间仍然没有反馈，操作系统内核将结束这次 IPC 调用，返回一个超时的错误。



#### 宏内核进程间通信

宏内核操作系统中进程间通信更多的是应用之间的交互，因此，设计的重心通常会放在接口的易用性、稳定性等方面。

##### 管道

##### 消息队列

##### 信号量

##### 共享内存

##### 信号

##### 套接字



## 内存管理

内存管理的目的是让不同的应用程序能够既**安全**又**高效**地共同使用物理内存资源。为此，操作系统在应用程序与物理内存之间加入了一个新的抽象：虚拟内存（virtual memory）。

### 虚拟内存

虚拟内存的**目的**是为了让物理内存扩充成**更大的逻辑内存**，从而让程序获得更多的可用内存。

操作系统将内存抽象成地址空间，每个应用程序都拥有一个独立而连续的虚拟地址空间；应用程序在运行时只能使用虚拟地址，CPU 负责将虚拟地址翻译成物理地址，操作系统**负责**设置**虚拟地址与物理地址之间的映射**（**配置段表或页表**）。

操作系统仅将应用程序实际使用的虚拟地址映射到物理地址，从而提高内存**资源的利用率**；每个应用程序只能看到自己的虚拟地址空间，从而保证不同应用程序所用内存之间的**隔离**；每个应用程序的虚拟地址空间是统一的、连续的，从而**降低了编程的复杂性**。



### 分段与分页机制

内存管理单元（Memory Management Unit，MMU），CPU 中的重要部件，负责虚拟地址到物理地址的转换。

包含：

+ TLB（Translation Lookaside Buffer）：是页表的高速缓存，存储着虚拟页号到物理页号的映射关系
+ Table Walk Unit：负责从页表中读取虚拟页对应的物理页地址

![](.\操作系统\MMU.png)



#### 翻译原理

MMU 将虚拟地址翻译为物理地址的主要机制有两种：分段机制和分页机制（主要机制）。

对于每次翻译，MMU 首先在 TLB 中检查有没有缓存，如果没有命中，根据页表基地址寄存器中存储的物理地址，Table Walk Unit 将从内存中的页表查询。

![](.\操作系统\MMU工作原理.jpg)



#### 分段

在分段机制下，操作系统以“段”（一段连续的物理内存）的形式管理/分配物理内存。应用程序的虚拟地址空间由若干个**不同大小**的段组成，比如代码段、数据段等。当 CPU 访问虚拟地址空间中某一个段的时候，MMU 会通过查询**段表**得到该段对应的物理内存区域。

段表存储着一个虚拟地址空间中**每一个分段**的信息，其中包括**段起始地址**（对应于物理内存中的起始物理地址）和**段长**。

虚拟地址由两部分构成：

+ 段号，标识着该虚拟地址属于整个虚拟地址空间中的哪一个段；
+ 段内地址（段内偏移）：即相对于该段起始地址的偏移量

注：在分段机制下，不仅虚拟内存空间被划分成不同的段，物理内存也以段为单位进行分配。在虚拟地址空间中，相邻的段所对应的物理内存中的段可以不相邻，因此，操作系统能够实现物理内存资源的离散分配。但这容易导致在物理内存上出现碎片空间（不足以映射给虚拟地址空间中的段），从而造成物理内存资源利用率的降低。



#### 分页

在分页机制下，应用程序的虚拟地址空间被划分为连续的、**等长**的虚拟页（区别于分段机制下不同长度的段），同时物理内存也被划分成连续的、等长的物理页。当 CPU 访问虚拟地址空间中某一页的时候，MMU 会通过查询**页表**得到该页对应的物理内存区域。

页表存储着虚拟页到物理页的**映射关系**，其中包括虚拟页号和物理页号。

虚拟地址由两部分构成：

+ 页号，标识着该虚拟地址属于整个虚拟地址空间中的哪一个页；
+ 页内偏移量：即相对于该页起始地址的偏移量

注：在分页机制下，应用程序虚拟地址空间的任意虚拟页可以被映射到物理内存中的任意物理页上，因此操作系统也能实现物理内存资源的离散分配。分页机制按照固定页大小分配物理内存，使得物理内存资源易于管理，可以有效避免分段机制中的外部碎片的问题。



##### 多级页表

单级页表可以看成以虚拟地址的虚拟页号作为索引的数组，整个数组的起始位置（物理地址）存储在页表基地址寄存器中。当翻译某个虚拟地址时，即根据其虚拟页号找到对应的数组项，因此整个页表必须在物理内存中连续，其中没有被用到的数组项也需要预留着（也就是说不能出现空洞）。这会造成页表**所占空间过大**，为了**压缩页表大小**，操作系统引入了多级结构的页表。

使用多级页表（假设有 k 级）时，一个虚拟地址中依然包括虚拟页号和页内偏移量，其中**虚拟页号**将被进一步地**划分成 k 个部分**（虚拟页号0...虚拟页号i，0 <= i < k）。**虚拟页号 i** 对应于该虚拟地址在**第 i 级**页表中的**索引**。当任意一级页表中的某一个条目为空时，该条目对应的下一级页表不需要存在（**允许出现空洞**），依次类推，接下来的页表同样不需要存在。因此，多级页表的设计极大减少了页表占用的空间大小。

###### 工作原理

![](.\操作系统\多级页表.jpg)

当 MMU 翻译一个**虚拟地址**的时候，首先根据**页表基地址寄存器**中的**物理地址**找到**第 0 级页表页**（该级有且仅有一个页表页），然后将虚拟地址的虚拟页号0作为页表项索引，读取第 0 级页表页中的相应页表项，**该页表项**中存储着**下一级页表页**的**物理地址**，依次类推，MMU 将在**最后一级页表页**中的**页表项**里找到**该虚拟地址**对应的**物理页号**，再结合**虚拟地址**中的**页偏移量**即可获得**最终的物理地址**。



###### TLB

多级页表结构能够显著地压缩页表大小，但多级页表结构使得 MMU 在翻译虚拟地址的过程中需要依次查找多个页表页中的页表项，一次地址翻译可能会导致多次物理地址内存访问。为了**减少**地址**翻译的次数**，MMU 引入**转址旁路缓存**（Translation Lookaside Buffer，TLB）部件来加速地址翻译的过程。



**TLB 刷新**

如果两个应用程序 A 和 B 使用了同样的虚拟地址 VA，但是对应于不同的物理地址 PA1 和 PA2。在应用程序 A 访问 VA 时，TLB会缓存 VA 到 PA1 的翻译；在切换到应用程序 B 运行后，尽管操作系统更新了 CPU 使用的页表基地址，但是当 B 访问 VA 时，CPU 如果依然从 TLB 中寻找 VA 的翻译，则会导致应用程序 B 的 VA 也被翻译成 PA1，进而产生访存的错误。

这个问题的根本原因在于：页表已经发生了变化，而 TLB 却没有做相应的更新，所有操作系统在页表切换（应用程序切换）的时候需要主动刷新 TLB。



### 换页与缺页异常

当物理层容量不够用的时候，操作系统会把若干物理页的内容写入类似于磁盘这种容量更大且更便宜的存储设备中，并且在应用程序的页表中去除对应虚拟页的映射，同时记录该物理页被换到磁盘上的对应位置，该过程称为物理页**换出（swap out）**，然后就可以回收这些物理页并分配给其他应用程序使用了。

当应用程序访问已分配但未映射至物理内存的虚拟页时，就会触发**缺页异常（page fault）**，此时 CPU 会运行操作系统预先设置的缺页异常处理函数，该函数会找到（也可能是通过换页的方式）一个空闲的物理页，将之前写到磁盘上的数据内容重新加载到该物理页中，并且在页表中填写虚拟地址到这一物理地址的映射，该过程称为物理页**换入（swap in）**



### 页替换策略

当需要**分配**物理页时，若空闲的物理页**已用完**或**小于**某个阈值，则操作系统将根据**页替换策略**选择一个或一些物理页**换出**到磁盘以便让出空间。

页替换策略是依据硬件所提供的页访问信息，来猜测哪些页**应该被换出**（比如短时间内再次被换入的概率较小的页），从而**最小化**缺页异常的**发生次数**以提升性能。

不同的页替换策略有各自适用的应用场景，常见的页替换策略有：

#### MIN策略/OPT策略

该策略在选择被换出页时，优先选择未来不会再访问的页，或者**在最长时间内不会再访问**的页。

该策略是理论最优的页替换策略，但在实际场景中很难实现，因为页访问顺序取决于应用程序，而操作系统通常无法预先得知应用程序未来访问顺序。该策略通常用来作为一个标准，衡量其他页替换策略的优劣。



#### FIFO策略

FIFO（First-In First-Out，先进先出）策略是最简单的页替换策略之一，其带来的时间开销很低。

该策略优先选择**最先换入**的页换出。操作系统维护一个队列用于记录换入内存的物理页号，每换入一个物理页就把其页号加到队尾，因此最先换入的物理页号总处于队头位置。当需要选择一个物理页换出时，该策略总是选择位于队列头部的物理页号所对应的物理页。

虽然该策略略直观且开销低，但它在实际使用中往往表现不佳（因为页换入顺序与使用是否频繁通常没有关联）。



#### Second Chance策略

Second Chance 策略是 FIFO 策略的一种改进版本。该策略的实现方法与 FIFO 策略类似，同样要求操作系统维护一个先进先出的队列用于记录换入物理内存的物理页号，此外还要为每一个物理页号维护一个访问标志位。如果访问的页号已经处在队列中，则置上其访问标志位。

在寻找将要换出的内存页时，该策略优先查看位于队头的页号，如果：

+ 它的访问标志位没有被置上，则换出该页号所对应的内存页
+ 它的访问标志位已经被置上，则将该标志位清零，并将该内存页号挪到队尾（将其当成一个最近访问的内存页的页号），并从新的队头开始重新寻找要换出的内存页



#### LRU策略

LRU（Least Recently Used）策略在选择被换出页时，优先选择**最久未被访问**的页。该策略的出发点在于：过去数条指令频繁访问的页很可能在后续的数条指令中也被频繁访问。

操作系统维护一个链表，按照内存页的访问顺序将内存页号插入链表中（最久未访问的内存页号在链表的首端，而最近访问的内存页号在链表尾端）；在每次内存访问后，操作系统把刚刚访问的内存页号调整到链表尾部；每次都选择换出位于链表首端的页，越不常访问的页号离首端越近。



#### MRU策略

与LRU策略相反，MRU（Most Recently Used）策略在替换内存页时，优先换出**最近访问**的内存页。该策略的出发点是：程序不会反复地访问相同的地址。



#### 时钟算法策略

时钟算法（clock algorithm）将**换入物理内存的页号**排成一个时钟的形状。该时钟有一个针臂，指向新换入内存的页号的后一个。同时，也为每一个页号维护一个访问标志位（访问位）。

每次需要选择换出页号时，该算法从针臂所指的页号开始检查，如果当前页号的访问位没有设置（即从上次检查到这次，该页没有被访问过），则将该页替换；如果当前页号的访问位已被设置（即被访问过），那就将其访问位清空，并且针臂顺时针移动到下一个页号。如此重复，直到找到一个访问位未被设置的页号。



## 文件系统



## 设备管理

